{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tidy Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook was posted by Simon Lindgren // [@simonlindgren](http://www.twitter.com/simonlindgren) // [simonlindgren.com](http://simonlindgren.com)\n",
    "\n",
    "It is about doing [LDA](https://en.wikipedia.org/wiki/Latent_Dirichlet_allocation) topic modelling with the R package [`topicmodels`](https://cran.r-project.org/web/packages/topicmodels/topicmodels.pdf) which provides an interface to the C code for LDA models (and also the CTM models) by [David Blei](https://en.wikipedia.org/wiki/David_Blei) and co-authors, and the C++ code for fitting LDA models using [Gibbs sampling](https://en.wikipedia.org/wiki/Gibbs_sampling) by [Phan and Nguyen](http://gibbslda.sourceforge.net).\n",
    "\n",
    "The code below draws on the book [Text Mining with R](http://tidytextmining.com) by [Julia Silge](http://juliasilge.com) and [David Robinson](http://varianceexplained.org)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(tidyverse)\n",
    "library(tidytext)\n",
    "library(tm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do do topic modelling with `tidytext`, we need a document-term-matrix (DTM) as input. We use here the DTM implementation of the `DocumentTermMatrix` class in the R package `tm`.\n",
    "\n",
    "So first, we use `tm` to create a DTM. Step one is to create a `corpus` from a directory of text files. In this example, the text files are in the directory `/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myCorpus <- Corpus(DirSource(\"data\"))\n",
    "summary(myCorpus) # Check what went in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We apply some cleaning of the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myCorpus <- tm_map(myCorpus, removeNumbers)\n",
    "myCorpus <- tm_map(myCorpus, removePunctuation)\n",
    "myCorpus <- tm_map(myCorpus , stripWhitespace)\n",
    "myCorpus <- tm_map(myCorpus, tolower)\n",
    "myCorpus <- tm_map(myCorpus, removeWords, stopwords(\"english\"))\n",
    "myCorpus <- tm_map(myCorpus, stemDocument, language = \"english\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, we create the DTM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "myDTM <-DocumentTermMatrix(myCorpus)\n",
    "myDTM <- removeSparseTerms(myDTM, 0.75) # can be adjusted, lower means smaller DTM\n",
    "myDTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(We don't need it for this particular analysis, but `tidytext` can also be used to tidy the DTM, that is, to turn it into a data frame with one-token-per-document-per-row. The tidied version includes only the non-zero values. It has no rows where count is zero.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tidyDTM <- tidy(myDTM)\n",
    "tidyDTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Topic Modelling\n",
    "Moving on, we use the `LDA()` function from the `topicmodels` package to fit an LDA model with `k` topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(topicmodels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtm_lda <- LDA(myDTM, k = 8)\n",
    "\n",
    "# Or: also set a seed so the model is predictable\n",
    "# dtm_lda <- LDA(myDTM, k = 2, control = list(seed = 1234))\n",
    "\n",
    "dtm_lda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we use the `tidy()` method to extract the per-topic-per-word probabilities (\"beta\") from the model.\n",
    "\n",
    "We get a dataframe in a one-topic-per-term-per-row format. For each combination, the model computes the probability of that term being generated from that topic.\n",
    "\n",
    "In the dataframe: A given '`term`' has a '`beta`' probability of being generated from a '`topic`'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics <- tidy(dtm_lda, matrix = \"beta\")\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this, we can use the `top_n()` function in the `dplyr` package to find the `n` number of terms that are most common within each topic. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_terms <- topics %>%\n",
    "  group_by(topic) %>%\n",
    "  top_n(10, beta) %>%\n",
    "  ungroup() %>%\n",
    "  arrange(topic, -beta)\n",
    "top_terms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, because this is a tidy data frame, it can be easily visualised through `ggplot2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualise the terms most common within each topic\n",
    "# = word-topic probabilities\n",
    "top_terms %>%\n",
    "  mutate(term = reorder(term, beta)) %>%\n",
    "  ggplot(aes(term, beta, fill = factor(topic))) +\n",
    "  geom_col(show.legend = FALSE) +\n",
    "  facet_wrap(~ topic, scales = \"free\") +\n",
    "  coord_flip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Topic differences\n",
    "We can also consider the terms that had the greatest difference in β between two chosen topics. We first tweak the dataframe with `mutate()` and `spread()`. Then we `filter()` for the relatively common words (that have a beta greater than .001 in at least one of the two topics). Finally we `mutate()` a column with the `log_ratio` (a symmetrical measure: β2 being twice as large leads to a log ratio of 1, while β1 being twice as large results in -1).\n",
    "\n",
    "Below, we do this for topic1 and topic2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_spread <- topics %>%\n",
    "  mutate(topic = paste0(\"topic\", topic))%>% # add 'topic' to the topic name\n",
    "  spread(topic, beta) %>% # spread to columns\n",
    "  filter(topic1 > .001 | topic2 > .001) %>% # choose the 2 topics to compare\n",
    "  mutate(log_ratio = log2(topic2 / topic1)) # choose topics to calculate\n",
    "beta_spread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then grab the top 10 and the bottom 10 log_ratios to get the words with the greatest differences (in both directions) between the two compared topics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_spread <- beta_spread %>%\n",
    "    arrange(desc(log_ratio)) # sort the dataframe by log ratio\n",
    "\n",
    "top10 <- beta_spread %>% # get the top 10\n",
    "    top_n(10)\n",
    "\n",
    "bottom10 <- beta_spread %>% # get the bottom 10\n",
    "    top_n(-10)\n",
    "\n",
    "top_bottom <- full_join(top10, bottom10) # join the top and bottom\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "top_bottom # includes all topics, but log_ratio columns is based on the two compared topics(above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot it\n",
    "top_bottom %>%\n",
    "    mutate(term = reorder(term, log_ratio))%>% #reorder terms by log_ratio to get correct bar order in graph\n",
    "    ggplot + # set up plot\n",
    "    aes(term, log_ratio, fill=log_ratio) + # plot terms by log ratio\n",
    "    geom_col()+ # choose col graph\n",
    "    coord_flip() # flip the view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Document-topic probabilities\n",
    "Now, we calculate gamma (document-topic probabilities) instead of beta (word-topic probabilities). \n",
    "\n",
    "In the resulting dataframe, the gamma values reflect the estimated proportion of words from a given document that are generated from a given topic."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics <- tidy(dtm_lda, matrix = \"gamma\")%>%\n",
    "    mutate(proportion = round(gamma,8)) %>%\n",
    "    arrange(desc(document), desc(proportion)) # sort by document, then proportion\n",
    "topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualise document topic proportions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topics %>%\n",
    "    ggplot(aes(document, proportion, fill = factor(topic))) + #variables\n",
    "    ggtitle(\"Topic proportions in documents\")+ # plot title\n",
    "    geom_col() + # plot type    \n",
    "    ylab(\"Topic proportions\")+ # y-axis title\n",
    "    xlab(\"Documents\")+ # x-axis title\n",
    "    scale_fill_discrete(name = \"Topics\") +# legend title\n",
    "    theme(legend.position = \"right\")+\n",
    "    coord_flip()\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Try a different visualisation\n",
    "topics %>%\n",
    "  mutate(document = reorder(document, gamma * topic)) %>%\n",
    "  ggplot(aes(factor(topic), gamma)) +\n",
    "  geom_col() +\n",
    "  facet_wrap(~ document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we find that a given document stands for a very large proportion of a given topic, we may want to view that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tidy(myDTM) %>%\n",
    "    filter(document == \"Jonna.txt\") %>%\n",
    "    arrange(desc(count))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
